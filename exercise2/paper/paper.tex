%x%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%   PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage{color}
\usepackage{float}
\usepackage{placeins}
\usepackage{natbib}
% philipp: added for code listings
\usepackage{listings}
\lstset{
    captionpos=b,
    basicstyle=\small
}
\newcommand{\Hilight}{\makebox[0pt][l]{\color{red}\rule[-4pt]{0.65\linewidth}{14pt}}}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{morefloats}
\bibliographystyle{plain}

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{todonotes}

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
% \renewcommand{\thesection}{Data Set \arabic{section}}
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength{\parskip}{\baselineskip}%
\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text
%----------------------------------------------------------------------------------------
%   TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{ 
\normalfont \normalsize 
\textsc{Vienna University of Technology} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Experiments in Machine Learning 2 \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Benjamin Kiesl \and Philipp Steinwender \and Robert Sch\"{a}fer} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%   PROBLEM 1
%----------------------------------------------------------------------------------------

\tableofcontents

%
%
%
\section{TODO}

\begin{itemize}
\item Implementation of cutsom bn-searcher
\item documentation of cutsom bn-searcher
\item comparison and interpretation of the results
\end{itemize}

%
%
%
\section{Preface}

This assignment is about extending a Bayes Network Classifier by adding a custom search algorithm. We chose the Hill Climber search algorithm for an implementation of an iterative local search algorithm.

%
%
%
\section{Setup}

There is a R script to execute the searcher in the handed in package at \texttt{R/bayesNetTest.R}. It loads Weka, builds the classifier, runs it and evaluates the model. It also shows the performance tables and the differences of the original Hill Climber implementation and our improved one. To run the script the following Tools need to be installed: R with the packages RWeka and rJava, Java (JRE).

The used package RWeka is an interface in R that wraps the Weka framework and has a really good documentation.

%
%
\section{BayesNet}

First we take a look at the BayesNet classifier implementation. When the classifier is startet, first thing is to generate the classification model. Therefore the BayesNet classifier initializes an adjacency matrix (\texttt{initStructure()}) where each attribute has an array of parents. These arrays are empty after initialization. 


\begin{lstlisting}[caption={Initialization of BayesNet},label=initStructure]
...
// initialize parent sets to have arrow from classifier node to
// each of the other nodes
for (int iAttribute = 0; iAttribute < instances.numAttributes(); iAttribute++) {
    if (iAttribute != iClass) {
        bayesNet.getParentSet(iAttribute).addParent(iClass, instances);
    }
}
...
\end{lstlisting}

The default Weka's SearchAlgorithm initializes the network like a Naive Bayes network. Listing \ref{initStructure} shows how we can use the adjacency matrix of BayesNet. Where \texttt{BayesNet} is the classifier that holds the network datastructure and \texttt{getParentSet(n)} returns the \texttt{nth} row in the adjacency matrix.

%
%
%
\section{Hill Climber}

Implementation of Weka's Hill Climber algorithm.

%
%
\subsection{Description}

As shown in listing \ref{hcSearch}, Hill Climber calculates an optimal solution based on the current network iteratively until no opration can be found to improve the network or the new network is only slightly better than the previous one. To find the best operation all possible operations get evaluated and the best one is returned. The algorithm stops, when it finds a local optima.

\begin{lstlisting}[caption={HillClimbers search algorithm},label=hcSearch]
double fScore = calcScore(bayesNet);
Operation oOperation = getOptimalOperation(bayesNet, instances);
while ((oOperation != null) && (oOperation.m_fScore > fScore)) {
	performOperation(bayesNet, instances, oOperation);
	fScore = oOperation.m_fScore;
	oOperation = getOptimalOperation(bayesNet, instances);
}  
\end{lstlisting}


%
%
\subsection{Test Results}

Two data sets are used to test the search algorithm. These are x and y from the assignment 1.

\todo{insert results of test}

As shown in the result listing, \todo{describe result} ....

%
%
%
\section{Extended Hill Climber}

To improve the Hill Climber algorithm we used it with an iterated local search algorithm.

\subsection{Description}

Like the Hill Climber, our improved search algorithm introduces an initial Naive Bayes like network where each attribute has the classification attribute as parent.

Then the Hill Climber algorithm is executed to find a local optima. To find other local optima, our search algorithm iteratively selects a neighbor of the found network and uses it as initial network for the Hill Climber to hopefully find better local optima than the first one.

 The intial network we use in each iteration is a random neighbor of the previously found one. It does not matter if it is better or worse.

If the Hill Climber finds a better network it is stored as the current best found network and if the seacher cannot find a better network after a given number of iterations, the algorithm stops and yields the best solution found.



%
%
%
\section{Comparison}

TODO:
* used datasets
* accuracy results
* runtime/performance


\bibliography{references}


\end{document}
%------------------------------------------------


